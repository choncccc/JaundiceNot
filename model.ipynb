{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RETRAIN \n",
    "# Install muna ako NVIDIA CUDA tas cuDNN para di sumabog PC "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.utils import shuffle\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.metrics import Precision, Recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load Images\n",
    "def load_images_and_labels(folder, label):\n",
    "    images = []\n",
    "    for file in os.listdir(folder):\n",
    "        image_path = os.path.join(folder, file)\n",
    "        image = tf.keras.utils.img_to_array(tf.keras.utils.load_img(image_path))\n",
    "        images.append(image.flatten())\n",
    "    labels = [label] * len(images)\n",
    "    return np.array(images), np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jaundiced images shape: (399, 120000)\n",
      "Jaundiced features shape: (399, 24)\n",
      "Healthy images shape: (497, 120000)\n",
      "Healthy features shape: (497, 24)\n",
      "float64\n",
      "[[177. 114.  79. ... 158. 111.  85.]\n",
      " [235. 219. 203. ... 237. 227. 217.]\n",
      " [149. 100.  70. ... 109.  72.  45.]\n",
      " [ 69.  69.  71. ...   7.   1.   1.]\n",
      " [198. 144. 120. ... 209. 164. 135.]]\n"
     ]
    }
   ],
   "source": [
    "#converts array [R][G][B]\n",
    "def process_rgb_columns(features_df):\n",
    "    rgb_columns = ['Cluster 1', 'Cluster 2', 'Cluster 3', 'Cluster 4', 'Cluster 5', 'Cluster 6']\n",
    "    processed_columns = []\n",
    "\n",
    "    for col in rgb_columns:\n",
    "        rgb_split = features_df[col].str.split(r'[-/]', expand=True)\n",
    "        rgb_split.columns = [f\"{col}_R\", f\"{col}_G\", f\"{col}_B\"]\n",
    "        \n",
    "        rgb_split = rgb_split.astype(int)\n",
    "        processed_columns.append(rgb_split)\n",
    "    processed_df = pd.concat(processed_columns, axis=1)\n",
    "    return processed_df\n",
    "\n",
    "\n",
    "# Load images + labels\n",
    "train_jaundiced_images, train_jaundiced_labels = load_images_and_labels(\"./train/train J\", 1)\n",
    "train_healthy_images, train_healthy_labels = load_images_and_labels(\"./train/train N\", 0)\n",
    "\n",
    "\n",
    "train_jaundiced_features_df = pd.read_csv(\"./features/jaundiced_features.csv\")\n",
    "train_healthy_features_df = pd.read_csv(\"./features/healthy_features.csv\")\n",
    "\n",
    "train_jaundiced_features_df = train_jaundiced_features_df.drop(columns=['Image'])\n",
    "train_healthy_features_df = train_healthy_features_df.drop(columns=['Image'])\n",
    "\n",
    "train_jaundiced_processed_features = process_rgb_columns(train_jaundiced_features_df)\n",
    "train_healthy_processed_features = process_rgb_columns(train_healthy_features_df)\n",
    "\n",
    "train_jaundiced_features = pd.concat([train_jaundiced_features_df.reset_index(drop=True), train_jaundiced_processed_features], axis=1).values\n",
    "train_healthy_features = pd.concat([train_healthy_features_df.reset_index(drop=True), train_healthy_processed_features], axis=1).values\n",
    "\n",
    "\n",
    "train_jaundiced = np.hstack((train_jaundiced_images, train_jaundiced_features))\n",
    "train_healthy = np.hstack((train_healthy_images, train_healthy_features))\n",
    "\n",
    "X_train = np.vstack((train_jaundiced, train_healthy))\n",
    "y_train = np.hstack((train_jaundiced_labels, train_healthy_labels))\n",
    "\n",
    "X_train, y_train = shuffle(X_train, y_train, random_state=1)\n",
    "\n",
    "test_jaundiced_images, test_jaundiced_labels = load_images_and_labels(\"./test/test J\", 1)\n",
    "test_healthy_images, test_healthy_labels = load_images_and_labels(\"./test/test N\", 0)\n",
    "\n",
    "val_jaundiced_images, val_jaundiced_labels = load_images_and_labels(\"./validate/validate J\", 1)\n",
    "val_healthy_images, val_healthy_labels = load_images_and_labels(\"./validate/validate N\", 0)\n",
    "\n",
    "# Combine test and validation (no annotations)\n",
    "X_test = np.vstack((test_jaundiced_images, test_healthy_images))\n",
    "y_test = np.hstack((test_jaundiced_labels, test_healthy_labels))\n",
    "\n",
    "X_val = np.vstack((val_jaundiced_images, val_healthy_images))\n",
    "y_val = np.hstack((val_jaundiced_labels, val_healthy_labels))\n",
    "\n",
    "\n",
    "X_train = pd.DataFrame(X_train).apply(pd.to_numeric, errors='coerce').values\n",
    "X_test = pd.DataFrame(X_test).apply(pd.to_numeric, errors='coerce').values\n",
    "X_val = pd.DataFrame(X_val).apply(pd.to_numeric, errors='coerce').values\n",
    "\n",
    "X_train = X_train[:, :120000] #need to trim kasi may excess na 24 features diko alam kung saan galing\n",
    "\n",
    "#prent\n",
    "print(\"Jaundiced images shape:\", train_jaundiced_images.shape)\n",
    "print(\"Jaundiced features shape:\", train_jaundiced_features.shape)\n",
    "print(\"Healthy images shape:\", train_healthy_images.shape)\n",
    "print(\"Healthy features shape:\", train_healthy_features.shape)\n",
    "print(X_train.dtype)\n",
    "print(X_train[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (896, 120000)\n",
      "X_test shape: (38, 120000)\n",
      "X_val shape: (18, 120000)\n"
     ]
    }
   ],
   "source": [
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"X_test shape:\", X_test.shape)\n",
    "print(\"X_val shape:\", X_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)  # Fit \n",
    "X_test = scaler.transform(X_test)       # Transform test data (images only with no annotations)\n",
    "X_val = scaler.transform(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\kenji\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "model = Sequential([\n",
    "    Dense(512, activation='relu', input_dim=X_train.shape[1]),  # Combined images + features\n",
    "    Dropout(0.3),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dropout(0.3),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.3),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dropout(0.3),\n",
    "    Dense(1, activation='sigmoid')  # Binary (J or N || 0 or 1)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 399ms/step - accuracy: 0.6262 - loss: 2.1106 - precision: 0.5935 - val_accuracy: 0.8333 - val_loss: 0.4131 - val_precision: 0.8571 - learning_rate: 1.0000e-04\n",
      "Epoch 2/30\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 383ms/step - accuracy: 0.6913 - loss: 2.6498 - precision: 0.6584 - val_accuracy: 0.8333 - val_loss: 0.8127 - val_precision: 0.8571 - learning_rate: 1.0000e-04\n",
      "Epoch 3/30\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 376ms/step - accuracy: 0.7369 - loss: 2.0893 - precision: 0.7161 - val_accuracy: 0.8889 - val_loss: 0.6649 - val_precision: 0.8750 - learning_rate: 1.0000e-04\n",
      "Epoch 4/30\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 379ms/step - accuracy: 0.7413 - loss: 2.0721 - precision: 0.7421 - val_accuracy: 0.9444 - val_loss: 0.3720 - val_precision: 0.8889 - learning_rate: 1.0000e-04\n",
      "Epoch 5/30\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 390ms/step - accuracy: 0.7580 - loss: 1.7521 - precision: 0.7224 - val_accuracy: 0.8889 - val_loss: 0.2815 - val_precision: 0.8750 - learning_rate: 1.0000e-04\n",
      "Epoch 6/30\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 383ms/step - accuracy: 0.7922 - loss: 1.8266 - precision: 0.7974 - val_accuracy: 0.8889 - val_loss: 0.2911 - val_precision: 0.8750 - learning_rate: 1.0000e-04\n",
      "Epoch 7/30\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 379ms/step - accuracy: 0.7698 - loss: 1.7020 - precision: 0.7450 - val_accuracy: 1.0000 - val_loss: 0.0840 - val_precision: 1.0000 - learning_rate: 1.0000e-04\n",
      "Epoch 8/30\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 378ms/step - accuracy: 0.8074 - loss: 1.5734 - precision: 0.8053 - val_accuracy: 0.8333 - val_loss: 0.3243 - val_precision: 0.7778 - learning_rate: 1.0000e-04\n",
      "Epoch 9/30\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 379ms/step - accuracy: 0.8001 - loss: 1.4436 - precision: 0.8124 - val_accuracy: 0.8889 - val_loss: 0.1571 - val_precision: 0.8750 - learning_rate: 1.0000e-04\n",
      "Epoch 10/30\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 388ms/step - accuracy: 0.8012 - loss: 1.3631 - precision: 0.7691 - val_accuracy: 0.8889 - val_loss: 0.3368 - val_precision: 0.8000 - learning_rate: 1.0000e-04\n",
      "Epoch 11/30\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 391ms/step - accuracy: 0.8217 - loss: 1.3304 - precision: 0.7833 - val_accuracy: 0.8889 - val_loss: 0.2653 - val_precision: 0.8000 - learning_rate: 1.0000e-05\n",
      "Epoch 12/30\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 380ms/step - accuracy: 0.8364 - loss: 1.2157 - precision: 0.8190 - val_accuracy: 0.8889 - val_loss: 0.2273 - val_precision: 0.8000 - learning_rate: 1.0000e-05\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.8147 - loss: 1.6476 - precision: 0.8791\n",
      "Test Loss: 1.6861, Test Accuracy: 0.8158, Test Precision: 0.8571\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer=Adam(learning_rate=0.0001), loss='binary_crossentropy', metrics=['accuracy', Precision()])\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "lr_scheduler = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=3)\n",
    "\n",
    "# Train\n",
    "history = model.fit(X_train, y_train, epochs=30, batch_size=32, validation_data=(X_val, y_val), callbacks=[early_stopping, lr_scheduler])\n",
    "\n",
    "# Evaluate \n",
    "loss, accuracy, precision = model.evaluate(X_test, y_test)\n",
    "print(f\"Test Loss: {loss:.4f}, Test Accuracy: {accuracy:.4f}, Test Precision: {precision:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No GPU detected. Ensure proper installation of TensorFlow, CUDA, and cuDNN.\n"
     ]
    }
   ],
   "source": [
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    print(\"GPUs available:\", gpus)\n",
    "else:\n",
    "    print(\"No GPU detected. Ensure proper installation of TensorFlow, CUDA, and cuDNN.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
