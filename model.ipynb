{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RETRAIN \n",
    "# Install muna ako NVIDIA CUDA tas cuDNN para di sumabog PC "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.utils import shuffle\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load Images\n",
    "def load_images_and_labels(folder, label):\n",
    "    images = []\n",
    "    for file in os.listdir(folder):\n",
    "        image_path = os.path.join(folder, file)\n",
    "        image = tf.keras.utils.img_to_array(tf.keras.utils.load_img(image_path))\n",
    "        images.append(image.flatten())\n",
    "    labels = [label] * len(images)\n",
    "    return np.array(images), np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jaundiced images shape: (399, 120000)\n",
      "Jaundiced features shape: (399, 24)\n",
      "Healthy images shape: (497, 120000)\n",
      "Healthy features shape: (497, 24)\n",
      "float64\n",
      "[[177. 114.  79. ... 158. 111.  85.]\n",
      " [235. 219. 203. ... 237. 227. 217.]\n",
      " [149. 100.  70. ... 109.  72.  45.]\n",
      " [ 69.  69.  71. ...   7.   1.   1.]\n",
      " [198. 144. 120. ... 209. 164. 135.]]\n"
     ]
    }
   ],
   "source": [
    "#converts array [R][G][B]\n",
    "def process_rgb_columns(features_df):\n",
    "    rgb_columns = ['Cluster 1', 'Cluster 2', 'Cluster 3', 'Cluster 4', 'Cluster 5', 'Cluster 6']\n",
    "    processed_columns = []\n",
    "\n",
    "    for col in rgb_columns:\n",
    "        rgb_split = features_df[col].str.split(r'[-/]', expand=True)\n",
    "        rgb_split.columns = [f\"{col}_R\", f\"{col}_G\", f\"{col}_B\"]\n",
    "        \n",
    "        rgb_split = rgb_split.astype(int)\n",
    "        processed_columns.append(rgb_split)\n",
    "    processed_df = pd.concat(processed_columns, axis=1)\n",
    "    return processed_df\n",
    "\n",
    "\n",
    "# Load images + labels\n",
    "train_jaundiced_images, train_jaundiced_labels = load_images_and_labels(\"./train/train J\", 1)\n",
    "train_healthy_images, train_healthy_labels = load_images_and_labels(\"./train/train N\", 0)\n",
    "\n",
    "\n",
    "train_jaundiced_features_df = pd.read_csv(\"./features/jaundiced_features.csv\")\n",
    "train_healthy_features_df = pd.read_csv(\"./features/healthy_features.csv\")\n",
    "\n",
    "train_jaundiced_features_df = train_jaundiced_features_df.drop(columns=['Image'])\n",
    "train_healthy_features_df = train_healthy_features_df.drop(columns=['Image'])\n",
    "\n",
    "train_jaundiced_processed_features = process_rgb_columns(train_jaundiced_features_df)\n",
    "train_healthy_processed_features = process_rgb_columns(train_healthy_features_df)\n",
    "\n",
    "train_jaundiced_features = pd.concat([train_jaundiced_features_df.reset_index(drop=True), train_jaundiced_processed_features], axis=1).values\n",
    "train_healthy_features = pd.concat([train_healthy_features_df.reset_index(drop=True), train_healthy_processed_features], axis=1).values\n",
    "\n",
    "\n",
    "train_jaundiced = np.hstack((train_jaundiced_images, train_jaundiced_features))\n",
    "train_healthy = np.hstack((train_healthy_images, train_healthy_features))\n",
    "\n",
    "X_train = np.vstack((train_jaundiced, train_healthy))\n",
    "y_train = np.hstack((train_jaundiced_labels, train_healthy_labels))\n",
    "\n",
    "X_train, y_train = shuffle(X_train, y_train, random_state=1)\n",
    "\n",
    "test_jaundiced_images, test_jaundiced_labels = load_images_and_labels(\"./test/test J\", 1)\n",
    "test_healthy_images, test_healthy_labels = load_images_and_labels(\"./test/test N\", 0)\n",
    "\n",
    "val_jaundiced_images, val_jaundiced_labels = load_images_and_labels(\"./validate/validate J\", 1)\n",
    "val_healthy_images, val_healthy_labels = load_images_and_labels(\"./validate/validate N\", 0)\n",
    "\n",
    "# Combine test and validation (no annotations)\n",
    "X_test = np.vstack((test_jaundiced_images, test_healthy_images))\n",
    "y_test = np.hstack((test_jaundiced_labels, test_healthy_labels))\n",
    "\n",
    "X_val = np.vstack((val_jaundiced_images, val_healthy_images))\n",
    "y_val = np.hstack((val_jaundiced_labels, val_healthy_labels))\n",
    "\n",
    "\n",
    "X_train = pd.DataFrame(X_train).apply(pd.to_numeric, errors='coerce').values\n",
    "X_test = pd.DataFrame(X_test).apply(pd.to_numeric, errors='coerce').values\n",
    "X_val = pd.DataFrame(X_val).apply(pd.to_numeric, errors='coerce').values\n",
    "\n",
    "X_train = X_train[:, :120000] #need to trim kasi may excess na 24 features diko alam kung saan galing\n",
    "\n",
    "#prent\n",
    "print(\"Jaundiced images shape:\", train_jaundiced_images.shape)\n",
    "print(\"Jaundiced features shape:\", train_jaundiced_features.shape)\n",
    "print(\"Healthy images shape:\", train_healthy_images.shape)\n",
    "print(\"Healthy features shape:\", train_healthy_features.shape)\n",
    "print(X_train.dtype)\n",
    "print(X_train[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (896, 120000)\n",
      "X_test shape: (38, 120000)\n",
      "X_val shape: (18, 120000)\n"
     ]
    }
   ],
   "source": [
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"X_test shape:\", X_test.shape)\n",
    "print(\"X_val shape:\", X_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)  # Fit \n",
    "X_test = scaler.transform(X_test)       # Transform test data (images only with no annotations)\n",
    "X_val = scaler.transform(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\kenji\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "model = Sequential([\n",
    "    Dense(512, activation='relu', input_dim=X_train.shape[1]),  # Combined images + features\n",
    "    Dropout(0.3),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dropout(0.3),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.3),\n",
    "    Dense(1, activation='sigmoid')  # Binary (J or N || 0 or 1)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 389ms/step - accuracy: 0.5896 - loss: 17.6236 - val_accuracy: 0.8889 - val_loss: 7.5617\n",
      "Epoch 2/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 366ms/step - accuracy: 0.7308 - loss: 17.5712 - val_accuracy: 0.9444 - val_loss: 1.4283\n",
      "Epoch 3/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 364ms/step - accuracy: 0.7837 - loss: 9.8336 - val_accuracy: 0.7778 - val_loss: 7.4412\n",
      "Epoch 4/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 382ms/step - accuracy: 0.7964 - loss: 7.6890 - val_accuracy: 0.8333 - val_loss: 1.3743\n",
      "Epoch 5/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 434ms/step - accuracy: 0.8391 - loss: 4.3197 - val_accuracy: 0.7222 - val_loss: 0.7454\n",
      "Epoch 6/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 444ms/step - accuracy: 0.8082 - loss: 3.4165 - val_accuracy: 0.8333 - val_loss: 0.4212\n",
      "Epoch 7/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 396ms/step - accuracy: 0.8110 - loss: 2.7955 - val_accuracy: 0.7778 - val_loss: 0.7981\n",
      "Epoch 8/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 391ms/step - accuracy: 0.8030 - loss: 2.4130 - val_accuracy: 0.8333 - val_loss: 0.5049\n",
      "Epoch 9/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 367ms/step - accuracy: 0.8444 - loss: 1.4405 - val_accuracy: 1.0000 - val_loss: 0.0729\n",
      "Epoch 10/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 367ms/step - accuracy: 0.8504 - loss: 1.1510 - val_accuracy: 0.9444 - val_loss: 0.1521\n",
      "Epoch 11/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 370ms/step - accuracy: 0.7874 - loss: 1.0619 - val_accuracy: 0.9444 - val_loss: 0.1417\n",
      "Epoch 12/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 425ms/step - accuracy: 0.8489 - loss: 0.6208 - val_accuracy: 0.8889 - val_loss: 0.2323\n",
      "Epoch 13/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 417ms/step - accuracy: 0.8602 - loss: 0.5412 - val_accuracy: 0.8333 - val_loss: 0.2558\n",
      "Epoch 14/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 395ms/step - accuracy: 0.8770 - loss: 0.4887 - val_accuracy: 0.9444 - val_loss: 0.2483\n",
      "Epoch 15/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 378ms/step - accuracy: 0.8769 - loss: 0.5842 - val_accuracy: 0.9444 - val_loss: 0.1961\n",
      "Epoch 16/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 400ms/step - accuracy: 0.8593 - loss: 0.4126 - val_accuracy: 0.9444 - val_loss: 0.1523\n",
      "Epoch 17/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 428ms/step - accuracy: 0.8914 - loss: 0.4195 - val_accuracy: 0.9444 - val_loss: 0.1901\n",
      "Epoch 18/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 414ms/step - accuracy: 0.8816 - loss: 0.2926 - val_accuracy: 0.9444 - val_loss: 0.1474\n",
      "Epoch 19/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 372ms/step - accuracy: 0.8923 - loss: 0.2925 - val_accuracy: 0.9444 - val_loss: 0.1514\n",
      "Epoch 20/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 370ms/step - accuracy: 0.8679 - loss: 0.4232 - val_accuracy: 0.8889 - val_loss: 0.2165\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.7971 - loss: 1.2356\n",
      "Test Loss: 1.2831, Test Accuracy: 0.7895\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer=Adam(learning_rate=0.001), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "history = model.fit(X_train, y_train, epochs=20, batch_size=32, validation_data=(X_val, y_val))\n",
    "\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(f\"Test Loss: {loss:.4f}, Test Accuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No GPU detected. Ensure proper installation of TensorFlow, CUDA, and cuDNN.\n"
     ]
    }
   ],
   "source": [
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    print(\"GPUs available:\", gpus)\n",
    "else:\n",
    "    print(\"No GPU detected. Ensure proper installation of TensorFlow, CUDA, and cuDNN.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
