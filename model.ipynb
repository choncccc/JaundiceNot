{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.utils import shuffle\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load Images\n",
    "def load_images_and_labels(folder, label):\n",
    "    images = []\n",
    "    for file in os.listdir(folder):\n",
    "        image_path = os.path.join(folder, file)\n",
    "        image = tf.keras.utils.img_to_array(tf.keras.utils.load_img(image_path))\n",
    "        images.append(image.flatten())\n",
    "    labels = [label] * len(images)\n",
    "    return np.array(images), np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jaundiced images shape: (399, 120000)\n",
      "Jaundiced features shape: (399, 24)\n",
      "Healthy images shape: (497, 120000)\n",
      "Healthy features shape: (497, 24)\n",
      "float64\n",
      "[[177. 114.  79. ... 158. 111.  85.]\n",
      " [235. 219. 203. ... 237. 227. 217.]\n",
      " [149. 100.  70. ... 109.  72.  45.]\n",
      " [ 69.  69.  71. ...   7.   1.   1.]\n",
      " [198. 144. 120. ... 209. 164. 135.]]\n"
     ]
    }
   ],
   "source": [
    "#converts array [R][G][B]\n",
    "def process_rgb_columns(features_df):\n",
    "    rgb_columns = ['Cluster 1', 'Cluster 2', 'Cluster 3', 'Cluster 4', 'Cluster 5', 'Cluster 6']\n",
    "    processed_columns = []\n",
    "\n",
    "    for col in rgb_columns:\n",
    "        rgb_split = features_df[col].str.split(r'[-/]', expand=True)\n",
    "        rgb_split.columns = [f\"{col}_R\", f\"{col}_G\", f\"{col}_B\"]\n",
    "        \n",
    "        rgb_split = rgb_split.astype(int)\n",
    "        processed_columns.append(rgb_split)\n",
    "    processed_df = pd.concat(processed_columns, axis=1)\n",
    "    return processed_df\n",
    "\n",
    "\n",
    "# Load images + labels\n",
    "train_jaundiced_images, train_jaundiced_labels = load_images_and_labels(\"./train/train J\", 1)\n",
    "train_healthy_images, train_healthy_labels = load_images_and_labels(\"./train/train N\", 0)\n",
    "\n",
    "\n",
    "train_jaundiced_features_df = pd.read_csv(\"./features/jaundiced_features.csv\")\n",
    "train_healthy_features_df = pd.read_csv(\"./features/healthy_features.csv\")\n",
    "\n",
    "train_jaundiced_features_df = train_jaundiced_features_df.drop(columns=['Image'])\n",
    "train_healthy_features_df = train_healthy_features_df.drop(columns=['Image'])\n",
    "\n",
    "train_jaundiced_processed_features = process_rgb_columns(train_jaundiced_features_df)\n",
    "train_healthy_processed_features = process_rgb_columns(train_healthy_features_df)\n",
    "\n",
    "train_jaundiced_features = pd.concat([train_jaundiced_features_df.reset_index(drop=True), train_jaundiced_processed_features], axis=1).values\n",
    "train_healthy_features = pd.concat([train_healthy_features_df.reset_index(drop=True), train_healthy_processed_features], axis=1).values\n",
    "\n",
    "\n",
    "train_jaundiced = np.hstack((train_jaundiced_images, train_jaundiced_features))\n",
    "train_healthy = np.hstack((train_healthy_images, train_healthy_features))\n",
    "\n",
    "X_train = np.vstack((train_jaundiced, train_healthy))\n",
    "y_train = np.hstack((train_jaundiced_labels, train_healthy_labels))\n",
    "\n",
    "X_train, y_train = shuffle(X_train, y_train, random_state=1)\n",
    "\n",
    "test_jaundiced_images, test_jaundiced_labels = load_images_and_labels(\"./test/test J\", 1)\n",
    "test_healthy_images, test_healthy_labels = load_images_and_labels(\"./test/test N\", 0)\n",
    "\n",
    "val_jaundiced_images, val_jaundiced_labels = load_images_and_labels(\"./validate/validate J\", 1)\n",
    "val_healthy_images, val_healthy_labels = load_images_and_labels(\"./validate/validate N\", 0)\n",
    "\n",
    "# Combine test and validation (no annotations)\n",
    "X_test = np.vstack((test_jaundiced_images, test_healthy_images))\n",
    "y_test = np.hstack((test_jaundiced_labels, test_healthy_labels))\n",
    "\n",
    "X_val = np.vstack((val_jaundiced_images, val_healthy_images))\n",
    "y_val = np.hstack((val_jaundiced_labels, val_healthy_labels))\n",
    "\n",
    "\n",
    "X_train = pd.DataFrame(X_train).apply(pd.to_numeric, errors='coerce').values\n",
    "X_test = pd.DataFrame(X_test).apply(pd.to_numeric, errors='coerce').values\n",
    "X_val = pd.DataFrame(X_val).apply(pd.to_numeric, errors='coerce').values\n",
    "\n",
    "X_train = X_train[:, :120000] #need to trim kasi may excess na 24 features diko alam kung saan galing\n",
    "\n",
    "#prent\n",
    "print(\"Jaundiced images shape:\", train_jaundiced_images.shape)\n",
    "print(\"Jaundiced features shape:\", train_jaundiced_features.shape)\n",
    "print(\"Healthy images shape:\", train_healthy_images.shape)\n",
    "print(\"Healthy features shape:\", train_healthy_features.shape)\n",
    "print(X_train.dtype)\n",
    "print(X_train[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (896, 120000)\n",
      "X_test shape: (38, 120000)\n",
      "X_val shape: (18, 120000)\n"
     ]
    }
   ],
   "source": [
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"X_test shape:\", X_test.shape)\n",
    "print(\"X_val shape:\", X_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)  # Fit \n",
    "X_test = scaler.transform(X_test)       # Transform test data (images only with no annotations)\n",
    "X_val = scaler.transform(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\kenji\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "model = Sequential([\n",
    "    Dense(512, activation='relu', input_dim=X_train.shape[1]),  # Combined images + features\n",
    "    Dropout(0.3),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dropout(0.3),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.3),\n",
    "    Dense(1, activation='sigmoid')  # Binary (J or N || 0 or 1)\n",
    "])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
